{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duskfallcrew/SDXL_COLAB_DIFFUSERS_CONVERT/blob/main/sdxl_to_diffusers_2025_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SDXL Model Converter Colab Edition**\n",
        "\n",
        "> ## **⚠️ IMPORTANT: Google Colab AUP Warning & Xformers Disclaimer ⚠️**\n",
        "---\n",
        "This Google Colab notebook is designed to convert Stable Diffusion XL (SDXL) model checkpoints to the `diffusers` format. It uses code from the `kohya-ss/sd-scripts` repository, which is primarily designed for training Stable Diffusion models and may cause the notebook to violate the Google Colab Acceptable Use Policy (AUP), even if you are not actively training a model.\n",
        "\n",
        "**Therefore, using this notebook carries a significant risk of AUP violations and may lead to the suspension of your Google Colab account. Use at your own risk.**\n",
        "\n",
        "Furthermore, the `xformers` library, which is installed as part of this notebook, may not be compatible with all hardware configurations or versions of PyTorch, and may cause errors or unexpected behavior. The reliability of this code and the functionality of `xformers` is entirely at your own risk.\n",
        "\n",
        "**This Notebook is Provided \"AS-IS\" with No Warranty or Guarantee of Functionality or Support.**\n",
        "\n",
        "\n",
        "---\n",
        "> ## Collaboration\n",
        "\n",
        ">I am NOT A programmer by nature, I patch with what little knowledge I have. I Failed programming several times over the years, so if something needs cleaning up and you want to patch it - pull request it!\n",
        "---\n",
        ">## About\n",
        "\n",
        "\n",
        ">We are a system of over 300 alters, proudly navigating life with Dissociative Identity Disorder, ADHD, Autism, and CPTSD. We believe in the potential of AI to break down barriers and enhance aspects of mental health, even as it presents challenges. Our creative journey is an ongoing exploration of identity and expression, and we invite you to join us in this adventure.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        ">## Credits:\n",
        "\n",
        "\n",
        "| Patched Origin | Description | Link |\n",
        "| --- | --- | --- |\n",
        "|Patched from| ARCHIVED |[SDXL - Linaqruf](https://colab.research.google.com/github/Linaqruf/sdxl-model-converter/blob/main/sdxl_model_converter.ipynb)\n",
        "|***Linaqruf @ Github***: |https://github.com/Linaqruf\n",
        "|Linaqruf Ko-Fi | [![](https://dcbadge.vercel.app/api/shield/850007095775723532?style=flat)](https://lookup.guru/850007095775723532) [![ko-fi](https://img.shields.io/badge/Support%20me%20on%20Ko--fi-F16061?logo=ko-fi&logoColor=white&style=flat)](https://ko-fi.com/linaqruf)\n",
        "| Linaqruf Saweria |<a href=\"https://saweria.co/linaqruf\"><img alt=\"Saweria\" src=\"https://img.shields.io/badge/Saweria-7B3F00?style=flat&logo=ko-fi&logoColor=white\"/></a>\n",
        ">## Social Media\n",
        "---\n",
        "| Link Name| Description | Link |\n",
        "| --- | --- | --- |\n",
        "| [Huggingface Backup](https://colab.research.google.com/github/kieranxsomer/HuggingFace_Backup/blob/main/HuggingFace_Backup.ipynb) | backup checkpoints! | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/kieranxsomer/HuggingFace_Backup/blob/main/HuggingFace_Backup.ipynb)\n",
        "|Discord| E&D Discord |[Invite](https://discord.gg/5t2kYxt7An)\n",
        "|CivitAi| Duskfallcrew @ Civitai |[Duskfallcrew](https://civitai.com/user/duskfallcrew/)\n",
        "|Huggingface| E&D Huggingface |[Earth & Dusk](https://huggingface.co/EarthnDusk)\n",
        "|Ko-Fi| Kofi Support |[![ko-fi](https://img.shields.io/badge/Support%20me%20on%20Ko--fi-F16061?logo=ko-fi&logoColor=white&style=flat)](https://ko-fi.com/Z8Z8L4EO)\n",
        "|Github| Duskfallcrew Github |[Duskfallcrew](https://github.com/duskfallcrew)\n",
        "| Youtube: | Duskfall Music|[Duskfall Music & More](https://www.youtube.com/channel/UCk7MGP7nrJz5awBSP75xmVw)\n",
        "| Spotify: | E&D Royalty Free| [PLAYLIST](https://open.spotify.com/playlist/00R8x00YktB4u541imdSSf?si=57a8f0f0fe87434e)\n",
        "|DA Group | AI Group| [DeviantArt Group](https://www.deviantart.com/diffusionai)\n",
        "| Reddit | Earth & Dusk| [Subreddit](https://www.reddit.com/r/earthndusk/)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "fL0y9tJdD-e0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> ## **Setup Instructions:**\n",
        "\n",
        "1.  **Google Colab Environment:** This notebook is designed to run on Google Colab with a GPU runtime enabled.\n",
        "2.  **Root Directory:** The `root_dir` variable specifies where files will be stored. The default is `/content`. You can specify a different location by changing the value in the corresponding text field.\n",
        "3. **Repository URL:** If you want to use a specific version of the `kohya-ss/sd-scripts` repository, then you can specify the URL using the text field for \"Repo URL\".\n",
        "4. **Branch Name:** If you want to use a specific branch of the `kohya-ss/sd-scripts` repository, then you can specify the branch name using the text field for \"Branch\".\n",
        "5. **Xformers URL:** You are using the official xformers library, however, if you have a custom built `xformers` wheel file, then you can specify the URL using the \"Xformers URL\" field. (Not Recommended).\n",
        "6.  **Run Setup:** After providing the values, click the \"Setup Environment\" button to install all required dependencies and clone the necessary files, and prepare the environment variables.\n",
        "7.  **Follow the Steps:** You are now able to continue with the following steps.\n",
        "\n",
        "---\n",
        "\n",
        "> ## **Important Note:**\n",
        "\n",
        "\n",
        "Before diving in, ensure you create a Hugging Face token with write permissions. Follow this link for instructions on token creation.\n",
        "\n",
        "You need to create a huggingface token, go to [this link](https://huggingface.co/settings/tokens), then `create new token` or copy available token with the `Write` role.\n",
        "\n",
        "-----------------\n"
      ],
      "metadata": {
        "id": "ltZ-gQ_iEyK5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "R3hfwYaXKn_V"
      },
      "outputs": [],
      "source": [
        "#@title ## **Install Kohya Script**\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "from ipywidgets import Text, Output, Button\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Create text widgets for input\n",
        "root_dir_widget = Text(value=\"/content\", placeholder=\"Root Directory\", description=\"Root Directory:\")\n",
        "repo_url_widget = Text(value=\"https://github.com/kohya-ss/sd-scripts\", placeholder=\"Repo URL\", description=\"Repo URL:\")\n",
        "branch_widget = Text(value=\"sdxl\", placeholder=\"Branch\", description=\"Branch:\")\n",
        "output_widget = Output()\n",
        "# Create a button to trigger the setup\n",
        "setup_button = Button(description=\"Setup Environment\")\n",
        "\n",
        "# Directories\n",
        "def setup_directories(root_dir):\n",
        "    repo_dir = os.path.join(root_dir, \"kohya-trainer\")\n",
        "    models_dir = os.path.join(root_dir, \"models\")\n",
        "    tools_dir = os.path.join(repo_dir, \"tools\")\n",
        "    vae_dir = os.path.join(root_dir, \"vae\")\n",
        "\n",
        "    os.makedirs(models_dir, exist_ok=True)\n",
        "    os.makedirs(vae_dir, exist_ok=True)\n",
        "    os.makedirs(tools_dir, exist_ok=True)\n",
        "    os.makedirs(repo_dir, exist_ok=True)\n",
        "    return repo_dir, models_dir, tools_dir, vae_dir\n",
        "\n",
        "\n",
        "def clone_repo(url, dir, branch, output_widget):\n",
        "    try:\n",
        "        if not os.path.exists(dir):\n",
        "            !git clone -b {branch} {url} {dir}\n",
        "    except Exception as e:\n",
        "        with output_widget:\n",
        "           print(f\"Error cloning repo: {e}\")\n",
        "\n",
        "def install_dependencies(output_widget):\n",
        "    try:\n",
        "        !apt install aria2\n",
        "        !pip install -q torch==2.1.0+cu121 diffusers[torch]==0.25.0 transformers==4.36.0 einops==0.6.0 open-clip-torch==2.20.0 invisible-watermark  jax[cuda12_pip]==0.4.23  -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "        !pip install -q xformers==0.0.23\n",
        "    except Exception as e:\n",
        "        with output_widget:\n",
        "            print(f\"Error installing dependencies: {e}\")\n",
        "\n",
        "def prepare_environment():\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"garbage_collection_threshold:0.9,max_split_size_mb:512\"\n",
        "    os.environ[\"TCMALLOC_AGGRESSIVE_DECOMMIT\"] = \"t\"\n",
        "    os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
        "\n",
        "def main(b):\n",
        "    root_dir = root_dir_widget.value\n",
        "    repo_url = repo_url_widget.value\n",
        "    branch = branch_widget.value\n",
        "    try:\n",
        "        repo_dir, models_dir, tools_dir, vae_dir = setup_directories(root_dir)\n",
        "        clone_repo(repo_url, repo_dir, branch, output_widget)\n",
        "        install_dependencies(output_widget)\n",
        "        prepare_environment()\n",
        "        with output_widget:\n",
        "            print(f\"Root directory set to: {root_dir}\")\n",
        "            print(\"Setup Complete\")\n",
        "    except Exception as e:\n",
        "         with output_widget:\n",
        "             print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "# Link the button to the main function\n",
        "setup_button.on_click(main)\n",
        "\n",
        "display(Markdown(\"\"\"\n",
        " **⚠️ WARNING:**\n",
        "This Google Colab notebook includes tools from the `kohya-ss/sd-scripts` repository, which is **primarily designed for training Stable Diffusion models**. Using this code may cause your Google Colab account to be flagged for violating the Google Colab Acceptable Use Policy (AUP), **even if you are not actively training a model**.\n",
        "\"\"\"))\n",
        "display(Markdown(\"\"\"\n",
        " **⚠️ IMPORTANT AUP RISK:**\n",
        " Using this notebook carries a **significant risk of AUP violations** which may lead to the suspension of your Google Colab account and it is provided **AS-IS** with no warranty or guarantee of support. **Use at your own risk.**\n",
        " \"\"\"))\n",
        "display(Markdown(\"\"\"\n",
        " **⚠️ XFORMERS WARNING:**\n",
        " The `xformers` library may not be compatible with all hardware configurations or versions of PyTorch, and it may lead to errors. The use of `xformers` and the reliability of this code is entirely at your own risk.\n",
        " \"\"\"))\n",
        "display(root_dir_widget)\n",
        "display(repo_url_widget)\n",
        "display(branch_widget)\n",
        "display(setup_button)\n",
        "display(output_widget)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### ♻ **Clean Folder**\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Function to clear and delete a folder\n",
        "def clear_and_delete_folder(colab_folder_path):\n",
        "    try:\n",
        "        # Use shutil.rmtree to remove all files and subdirectories\n",
        "        shutil.rmtree(colab_folder_path)\n",
        "        display(Markdown(f\"Deleted all contents in folder: `{colab_folder_path}`\"))\n",
        "    except Exception as e:\n",
        "        display(Markdown(f\"Error deleting folder `{colab_folder_path}`: {e}\"))\n",
        "\n",
        "# @markdown ### Folder Path for Deletion\n",
        "\n",
        "colab_folder_path = \"\" # @param {type: \"string\"}\n",
        "\n",
        "# Call the function to clear and delete the folder\n",
        "clear_and_delete_folder(colab_folder_path)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sRiX3jnynw3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### ♻ **Fix Before Converting (Optional, may not work)**\n",
        "#@markdown This MAY not work for SDXL, if you require key fixings and this works let me know!\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "from safetensors import safe_open\n",
        "from safetensors.torch import save_file\n",
        "import os\n",
        "\n",
        "display(Markdown(\"\"\"\n",
        " **⚠️ WARNING:**\n",
        " This Google Colab notebook includes tools from the `kohya-ss/sd-scripts` repository. This code is primarily designed for training Stable Diffusion models and it may cause the notebook to violate the Google Colab Acceptable Use Policy (AUP) even if you are not actively training a model. The use of `kohya-ss` may flag your account and you may be unable to run this notebook.\n",
        "\"\"\"))\n",
        "display(Markdown(\"\"\"\n",
        " **⚠️ IMPORTANT:**\n",
        " Using this notebook carries a significant risk of AUP violations and may lead to the suspension of your account. Use at your own risk.\n",
        " \"\"\"))\n",
        "display(Markdown(\"\"\"\n",
        " **⚠️ XFORMERS WARNING:**\n",
        " The `xformers` library may not be compatible with all hardware configurations or versions of PyTorch, and it may lead to errors. The use of `xformers` and the reliability of this code is entirely at your own risk.\n",
        " \"\"\"))\n",
        "\n",
        "#@markdown ### Model Type\n",
        "model_type = \"\" # @param [\"\", \"vae\"]\n",
        "\n",
        "#@markdown ### Input path\n",
        "load_path = \"\" # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ### Output path\n",
        "save_path = \"\" # @param {type: \"string\"}\n",
        "\n",
        "\n",
        "def fix_diffusers_model_conversion(load_path, save_path, model_type):\n",
        "   try:\n",
        "\n",
        "    # load original\n",
        "    tensors = {}\n",
        "    with safe_open(load_path, framework=\"pt\") as f:\n",
        "        for key in f.keys():\n",
        "            tensors[key] = f.get_tensor(key)\n",
        "\n",
        "        # migrate\n",
        "        new_tensors = {}\n",
        "        for k, v in tensors.items():\n",
        "            new_key = k\n",
        "            # only fix the vae\n",
        "            if model_type == \"vae\" and 'first_stage_model.' in k:\n",
        "                # migrate q, k, v keys\n",
        "                new_key = new_key.replace('.to_q.weight', '.q.weight')\n",
        "                new_key = new_key.replace('.to_q.bias', '.q.bias')\n",
        "                new_key = new_key.replace('.to_k.weight', '.k.weight')\n",
        "                new_key = new_key.replace('.to_k.bias', '.k.bias')\n",
        "                new_key = new_key.replace('.to_v.weight', '.v.weight')\n",
        "                new_key = new_key.replace('.to_v.bias', '.v.bias')\n",
        "            new_tensors[new_key] = v\n",
        "\n",
        "        # save\n",
        "        save_file(new_tensors, save_path)\n",
        "        display(Markdown(f\"Keys have been fixed and the model saved to {save_path}\"))\n",
        "\n",
        "   except Exception as e:\n",
        "       display(Markdown(f\"An error occurred during key fixing: {e}\"))\n",
        "\n",
        "# Example usage\n",
        "fix_diffusers_model_conversion(load_path, save_path, model_type)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NiWfPWulD6rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Download XL MODELS**\n",
        "\n",
        "**⚠️ WARNING:**\n",
        "THIS CELL ALLOWS YOU TO DOWNLOAD STABLE DIFFUSION XL MODELS INTO YOUR GOOGLE COLABORATORY NOTEBOOK. PLEASE BE AWARE THIS MAY BE OF VIOLATION OF YOUR AUP.\n",
        "\n",
        "**⚠️ IMPORTANT:**\n",
        "Using this notebook carries a significant risk of AUP violations and may lead to the suspension of your account. Use at your own risk.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. You must specify a Hugging Face Token if the model you are downloading is in a private Hugging Face Repository.\n",
        "2. You must specify a URL to an SDXL model, which can be a Google Drive Link, a Hugging Face Model or direct URL to a file.\n",
        "3. You may optionally specify a folder where you would like to save the file. If you do not specify one, it will be stored in `/content/models` folder.\n",
        "4. Click the \"Download SDXL Model\" to begin the process."
      ],
      "metadata": {
        "id": "LIqXsFm2HlPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download SDXL**\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import glob\n",
        "import gdown\n",
        "import requests\n",
        "import subprocess\n",
        "from urllib.parse import urlparse, unquote\n",
        "from pathlib import Path\n",
        "from ipywidgets import Text, Button, Output\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(\"\"\"\n",
        " **⚠️ WARNING:**\n",
        " This Google Colab notebook includes tools from the `kohya-ss/sd-scripts` repository. This code is primarily designed for training Stable Diffusion models and it may cause the notebook to violate the Google Colab Acceptable Use Policy (AUP) even if you are not actively training a model. The use of `kohya-ss` may flag your account and you may be unable to run this notebook.\n",
        "\"\"\"))\n",
        "display(Markdown(\"\"\"\n",
        " **⚠️ IMPORTANT:**\n",
        " Using this notebook carries a significant risk of AUP violations and may lead to the suspension of your account. Use at your own risk.\n",
        " \"\"\"))\n",
        "display(Markdown(\"\"\"\n",
        " **⚠️ XFORMERS WARNING:**\n",
        " The `xformers` library may not be compatible with all hardware configurations or versions of PyTorch, and it may lead to errors. The use of `xformers` and the reliability of this code is entirely at your own risk.\n",
        " \"\"\"))\n",
        "\n",
        "\n",
        "# @markdown Place your Huggingface [Read Token](https://huggingface.co/settings/tokens) Here.\n",
        "HUGGINGFACE_TOKEN = \"\"#@param {type: \"string\"}\n",
        "\n",
        "# @markdown Place your SDXL Model URL Here.\n",
        "SDXL_MODEL_URL = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Specify the output path for the files here\n",
        "OUTPUT_PATH = \"/content/models\" #@param {type: \"string\"}\n",
        "\n",
        "# Create a button to trigger the download\n",
        "download_button = Button(description=\"Download SDXL Model\")\n",
        "\n",
        "# Create an output widget to display the results\n",
        "output_widget = Output()\n",
        "\n",
        "\n",
        "def get_supported_extensions():\n",
        "    return tuple([\".ckpt\", \".safetensors\", \".pt\", \".pth\"])\n",
        "\n",
        "def get_filename(url):\n",
        "    extensions = get_supported_extensions()\n",
        "\n",
        "    if url.endswith(tuple(extensions)):\n",
        "        filename = os.path.basename(url)\n",
        "    else:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        if 'content-disposition' in response.headers:\n",
        "            content_disposition = response.headers['content-disposition']\n",
        "            filename = re.findall('filename=\"?([^\"]+)\"?', content_disposition)[0]\n",
        "        else:\n",
        "            url_path = urlparse(url).path\n",
        "            filename = unquote(os.path.basename(url_path))\n",
        "\n",
        "    if filename.endswith(tuple(get_supported_extensions())):\n",
        "        return filename\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def parse_args(config):\n",
        "    args = []\n",
        "\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args.append(f\"{v}\")\n",
        "        elif isinstance(v, str) and v is not None:\n",
        "            args.append(f'--{k}={v}')\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args.append(f\"--{k}\")\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args.append(f\"--{k}={v}\")\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args.append(f\"--{k}={v}\")\n",
        "\n",
        "    return args\n",
        "\n",
        "def aria2_download(dir, filename, url, huggingface_token):\n",
        "    user_header = f\"Authorization: Bearer {huggingface_token}\"\n",
        "\n",
        "    aria2_config = {\n",
        "        \"console-log-level\"         : \"error\",\n",
        "        \"summary-interval\"          : 10,\n",
        "        \"header\"                    : user_header if \"huggingface.co\" in url else None,\n",
        "        \"continue\"                  : True,\n",
        "        \"max-connection-per-server\" : 16,\n",
        "        \"min-split-size\"            : \"1M\",\n",
        "        \"split\"                     : 16,\n",
        "        \"dir\"                       : dir,\n",
        "        \"out\"                       : filename,\n",
        "        \"_url\"                      : url,\n",
        "    }\n",
        "    aria2_args = parse_args(aria2_config)\n",
        "    subprocess.run([\"aria2c\", *aria2_args])\n",
        "\n",
        "def gdown_download(url, dst, filepath):\n",
        "    if \"/uc?id/\" in url or \"/file/d/\" in url:\n",
        "        return gdown.download(url, filepath, quiet=False)\n",
        "    elif \"/drive/folders/\" in url:\n",
        "        os.chdir(dst)\n",
        "        return gdown.download_folder(url, quiet=True, use_cookies=False)\n",
        "\n",
        "def download(url, dst, huggingface_token, output_widget):\n",
        "    filename = get_filename(url)\n",
        "    filepath = os.path.join(dst, filename)\n",
        "\n",
        "    try:\n",
        "        if \"drive.google.com\" in url:\n",
        "            gdown = gdown_download(url, dst, filepath)\n",
        "        elif url.startswith(\"/content/drive/MyDrive/\"):\n",
        "            return url\n",
        "        else:\n",
        "            if \"huggingface.co\" in url:\n",
        "                if \"/blob/\" in url:\n",
        "                    url = url.replace(\"/blob/\", \"/resolve/\")\n",
        "            aria2_download(dst, filename, url, huggingface_token)\n",
        "        with output_widget:\n",
        "            print(f\"Model downloaded to: {dst}\")\n",
        "    except Exception as e:\n",
        "       with output_widget:\n",
        "            print(f\"An error occurred during the download: {e}\")\n",
        "\n",
        "\n",
        "def main(b):\n",
        "    try:\n",
        "      download(SDXL_MODEL_URL, OUTPUT_PATH, HUGGINGFACE_TOKEN, output_widget)\n",
        "    except Exception as e:\n",
        "      with output_widget:\n",
        "        print(f\"An error occurred in the main function: {e}\")\n",
        "\n",
        "\n",
        "# Link the button to the main function\n",
        "download_button.on_click(main)\n",
        "\n",
        "\n",
        "display(download_button)\n",
        "display(output_widget)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_nmd5ciZKv3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CONVERT SDXL MODELS**\n",
        "\n",
        "**⚠️ WARNING:**\n",
        "THIS CELL ALLOWS YOU TO CONVERT STABLE DIFFUSION MODELS, WHICH CAN BE CONSIDERED NSFW OR SIGNIFICANT RISK TO AUP VIOLATIONS and may lead to the suspension of your account. Use at your own risk.\n",
        "\n",
        "**⚠️ IMPORTANT:**\n",
        "Using this notebook carries a significant risk of AUP violations and may lead to the suspension of your account. Use at your own risk.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "l_lJ0Kr6Im8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Convert SDXL to Diffusers**\n",
        "import os\n",
        "import urllib.request\n",
        "from ipywidgets import Text, Button, Output\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(\"\"\"\n",
        " **⚠️ WARNING:**\n",
        " This Google Colab notebook includes tools from the `kohya-ss/sd-scripts` repository. This code is primarily designed for training Stable Diffusion models and it may cause the notebook to violate the Google Colab Acceptable Use Policy (AUP) even if you are not actively training a model. The use of `kohya-ss` may flag your account and you may be unable to run this notebook.\n",
        "\"\"\"))\n",
        "display(Markdown(\"\"\"\n",
        " **⚠️ IMPORTANT:**\n",
        " Using this notebook carries a significant risk of AUP violations and may lead to the suspension of your account. Use at your own risk.\n",
        " \"\"\"))\n",
        "display(Markdown(\"\"\"\n",
        " **⚠️ XFORMERS WARNING:**\n",
        " The `xformers` library may not be compatible with all hardware configurations or versions of PyTorch, and it may lead to errors. The use of `xformers` and the reliability of this code is entirely at your own risk.\n",
        " \"\"\"))\n",
        "#@markdown ### **Conversion Config**\n",
        "model_to_load = \"\" #@param {'type': 'string'}\n",
        "script_url = \"https://raw.githubusercontent.com/duskfallcrew/sdxl-model-converter/main/convert_sdxl_to_diffusers.py\" #@param {'type': 'string'}\n",
        "global_step = 0 #@param {type:\"integer\"}\n",
        "epoch = 0 #@param {type:\"integer\"}\n",
        "save_precision_as = \"fp16\" #@param [\"fp16\",\"bf16\",\"float\"] {'allow-input': false}\n",
        "reference_model = \"stabilityai/stable-diffusion-xl-base-1.0\" #@param {'type': 'string'}\n",
        "output_path = \"/content/output\" #@param {type: \"string\"}\n",
        "\n",
        "# Create a button to trigger the conversion\n",
        "convert_button = Button(description=\"Convert SDXL to Diffusers\")\n",
        "output_widget = Output()\n",
        "\n",
        "def convert_dict(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "    return args\n",
        "\n",
        "def check_and_download_script(script_name, script_url):\n",
        "    try:\n",
        "        if not os.path.exists(script_name):\n",
        "            with output_widget:\n",
        "                print(f\"{script_name} not found, downloading...\")\n",
        "            urllib.request.urlretrieve(script_url, script_name)\n",
        "    except Exception as e:\n",
        "      with output_widget:\n",
        "          print(f\"An error occurred during downloading: {e}\")\n",
        "          return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def run_script(script_name, script_args, output_widget):\n",
        "  try:\n",
        "      !python {script_name} {script_args}\n",
        "      with output_widget:\n",
        "        print(f\"Conversion complete to {output_path}!\")\n",
        "  except Exception as e:\n",
        "    with output_widget:\n",
        "      print(f\"An error occurred during conversion: {e}\")\n",
        "\n",
        "\n",
        "def main(b):\n",
        "    if not check_and_download_script(\"convert_sdxl_to_diffusers.py\", script_url):\n",
        "        return\n",
        "\n",
        "    config = {\n",
        "        \"model_to_load\": model_to_load,\n",
        "        \"save_precision_as\": save_precision_as,\n",
        "        \"epoch\": epoch,\n",
        "        \"global_step\": global_step,\n",
        "        \"reference_model\": reference_model,\n",
        "        \"output_path\": output_path\n",
        "    }\n",
        "    run_script(\"convert_sdxl_to_diffusers.py\", convert_dict(config), output_widget)\n",
        "\n",
        "# Link the button to the main function\n",
        "convert_button.on_click(main)\n",
        "\n",
        "# Display the widgets\n",
        "display(convert_button)\n",
        "display(output_widget)"
      ],
      "metadata": {
        "id": "uSEEJiDaK3Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Deploy**"
      ],
      "metadata": {
        "id": "sjtc_ZNaTpUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### **Huggingface Hub config**\n",
        "from huggingface_hub import login, HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "\n",
        "# @markdown Login to Huggingface Hub\n",
        "# @markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
        "write_token = \"\"  # @param {type:\"string\"}\n",
        "# @markdown Fill this if you want to upload to your organization, or just leave it empty.\n",
        "orgs_name = \"\"  # @param{type:\"string\"}\n",
        "# @markdown If your model repo does not exist, it will automatically create it.\n",
        "model_name = \"\"  # @param {type:\"string\"}\n",
        "make_private = False  # @param{type:\"boolean\"}\n",
        "\n",
        "def authenticate(write_token):\n",
        "    login(write_token, add_to_git_credential=True)\n",
        "    api = HfApi()\n",
        "    return api.whoami(write_token), api\n",
        "\n",
        "def create_model_repo(api, user, orgs_name, model_name, make_private=False):\n",
        "    if orgs_name == \"\":\n",
        "        repo_id = user[\"name\"] + \"/\" + model_name.strip()\n",
        "    else:\n",
        "        repo_id = orgs_name + \"/\" + model_name.strip()\n",
        "\n",
        "    try:\n",
        "        validate_repo_id(repo_id)\n",
        "        api.create_repo(repo_id=repo_id, repo_type=\"model\", private=make_private)\n",
        "        print(f\"Model repo '{repo_id}' didn't exist, creating repo\")\n",
        "    except HfHubHTTPError as e:\n",
        "        print(f\"Model repo '{repo_id}' exists, skipping create repo\")\n",
        "\n",
        "    print(f\"Model repo '{repo_id}' link: https://huggingface.co/{repo_id}\\n\")\n",
        "\n",
        "    return repo_id\n",
        "\n",
        "user, api = authenticate(write_token)\n",
        "\n",
        "if model_name:\n",
        "    model_repo = create_model_repo(api, user, orgs_name, model_name, make_private)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pU3wMdOeXE4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### ♻ **Upload to Huggingface**\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# @markdown This will be uploaded to model repo\n",
        "model_path = \"\"  # @param {type :\"string\"}\n",
        "path_in_repo = \"\"  # @param {type :\"string\"}\n",
        "project_name = os.path.basename(model_path)\n",
        "\n",
        "# @markdown Other Information\n",
        "commit_message = \"Upload with 🚀🤗 E&D SDXL Diffusers notebook\"  # @param {type :\"string\"}\n",
        "\n",
        "def is_diffusers_model(model_path):\n",
        "    required_folders = {\"unet\", \"text_encoder\", \"text_encoder_2\", \"tokenizer\", \"tokenizer_2\", \"scheduler\", \"vae\"}\n",
        "    return required_folders.issubset(set(os.listdir(model_path))) and os.path.isfile(os.path.join(model_path, \"model_index.json\"))\n",
        "\n",
        "def upload_model(model_paths, is_folder: bool):\n",
        "    path_obj = Path(model_paths)\n",
        "    trained_model = path_obj.parts[-1]\n",
        "\n",
        "    path_in_repo_local = path_in_repo if path_in_repo and not is_diffusers_model(model_paths) else \"\"\n",
        "\n",
        "    notification = f\"Uploading {trained_model} from {model_paths} to https://huggingface.co/{model_repo}\"\n",
        "    print(notification)\n",
        "\n",
        "    if is_folder:\n",
        "        if is_diffusers_model(model_paths):\n",
        "            commit_message = f\"Upload diffusers format: {trained_model}\"\n",
        "            print(\"Detected diffusers model. Adjusting upload parameters.\")\n",
        "        else:\n",
        "            commit_message = f\"Upload checkpoint: {trained_model}\"\n",
        "            print(\"Detected regular model. Adjusting upload parameters.\")\n",
        "\n",
        "        api.upload_folder(\n",
        "            folder_path=model_paths,\n",
        "            path_in_repo=path_in_repo_local,\n",
        "            repo_id=model_repo,\n",
        "            commit_message=commit_message,\n",
        "            ignore_patterns=\".ipynb_checkpoints\",\n",
        "        )\n",
        "    else:\n",
        "        commit_message = f\"Upload file: {trained_model}\"\n",
        "        api.upload_file(\n",
        "            path_or_fileobj=model_paths,\n",
        "            path_in_repo=path_in_repo_local,\n",
        "            repo_id=model_repo,\n",
        "            commit_message=commit_message,\n",
        "        )\n",
        "\n",
        "    success_notification = f\"♻ Model upload complete, care to try again? Thanks for flying Stable Diffusion Airlines, you owe me five dollars.. Check the model at https://huggingface.co/{model_repo}/tree/main\"\n",
        "    print(success_notification)\n",
        "\n",
        "def upload():\n",
        "    if model_path.endswith((\".ckpt\", \".safetensors\", \".pt\")):\n",
        "        upload_model(model_path, False)\n",
        "    else:\n",
        "        upload_model(model_path, True)\n",
        "\n",
        "upload()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YPzfmu_4DtWG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
